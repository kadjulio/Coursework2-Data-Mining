{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy import stats\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CSV to ARFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Since we are using Python, we do  not need to complete this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"../../data/raw/\"\n",
    "\n",
    "X = pd.read_csv(f\"{file_path}x_train_gr_smpl.csv\", delimiter=',')\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# image = X.loc[[600]].values\n",
    "# image = image[0].reshape((48,48))\n",
    "# image.shape\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Y = pd.read_csv(f\"{file_path}y_train_smpl.csv\", delimiter=',')\n",
    "Y.columns = ['target']\n",
    "\n",
    "y0 = pd.read_csv(f\"{file_path}y_train_smpl_0.csv\", delimiter=',')\n",
    "y0.columns = ['target']\n",
    "\n",
    "y1 = pd.read_csv(f\"{file_path}y_train_smpl_1.csv\", delimiter=',')\n",
    "y1.columns = ['target']\n",
    "\n",
    "y2 = pd.read_csv(f\"{file_path}y_train_smpl_2.csv\", delimiter=',')\n",
    "y2.columns = ['target']\n",
    "\n",
    "y3 = pd.read_csv(f\"{file_path}y_train_smpl_3.csv\", delimiter=',')\n",
    "y3.columns = ['target']\n",
    "\n",
    "y4 = pd.read_csv(f\"{file_path}y_train_smpl_4.csv\", delimiter=',')\n",
    "y4.columns = ['target']\n",
    "\n",
    "y5 = pd.read_csv(f\"{file_path}y_train_smpl_5.csv\", delimiter=',')\n",
    "y5.columns = ['target']\n",
    "\n",
    "y6 = pd.read_csv(f\"{file_path}y_train_smpl_6.csv\", delimiter=',')\n",
    "y6.columns = ['target']\n",
    "\n",
    "y7 = pd.read_csv(f\"{file_path}y_train_smpl_7.csv\", delimiter=',')\n",
    "y7.columns = ['target']\n",
    "\n",
    "y8 = pd.read_csv(f\"{file_path}y_train_smpl_8.csv\", delimiter=',')\n",
    "y8.columns = ['target']\n",
    "\n",
    "y9 = pd.read_csv(f\"{file_path}y_train_smpl_9.csv\", delimiter=',')\n",
    "y9.columns = ['target']\n",
    "\n",
    "Y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# train_smpl_0 = pd.concat([X, y0], axis=1)\n",
    "# train_smpl_1 = pd.concat([X, y1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# train_smpl_2 = pd.concat([X, y2], axis=1)\n",
    "# train_smpl_3 = pd.concat([X, y3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# train_smpl_4 = pd.concat([X, y4], axis=1)\n",
    "# train_smpl_5 = pd.concat([X, y5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# train_smpl_6 = pd.concat([X, y6], axis=1)\n",
    "# train_smpl_7 = pd.concat([X, y7], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# train_smpl_8 = pd.concat([X, y8], axis=1)\n",
    "# train_smpl_9 = pd.concat([X, y9], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_smpl = pd.concat([X, Y], axis=1)\n",
    "train_smpl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Randomisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.utils.suffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_smpl = shuffle(train_smpl, random_state=42)\n",
    "# train_smpl_0 = shuffle(train_smpl_0, random_state=42)\n",
    "# train_smpl_1 = shuffle(train_smpl_1, random_state=42)\n",
    "# train_smpl_2 = shuffle(train_smpl_2, random_state=42)\n",
    "# train_smpl_3 = shuffle(train_smpl_3, random_state=42)\n",
    "# train_smpl_4 = shuffle(train_smpl_4, random_state=42)\n",
    "# train_smpl_5 = shuffle(train_smpl_5, random_state=42)\n",
    "# train_smpl_6 = shuffle(train_smpl_6, random_state=42)\n",
    "# train_smpl_7 = shuffle(train_smpl_7, random_state=42)\n",
    "# train_smpl_8 = shuffle(train_smpl_8, random_state=42)\n",
    "# train_smpl_9 = shuffle(train_smpl_9, random_state=42)\n",
    "train_smpl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#train_smpl.hist(column='target')\n",
    "plt.hist(Y['target'], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_smpl.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reducing the size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because the data runs the data as a Python file, we do not need to reduce the size of our data set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_smpl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "oversample_ratio={2: 1000,  6: 1000, 7: 1000, 9: 1000}\n",
    "undersample_ratio={0: 1000, 1: 1000,  3: 1000, 4: 1000, 5: 1000, 8: 1000}\n",
    "pipe = make_pipeline(SMOTE(sampling_strategy=oversample_ratio, n_jobs=7), NearMiss(sampling_strategy=undersample_ratio, n_jobs=7))\n",
    "\n",
    "X_resampled, y_resampled = pipe.fit_resample(X, Y['target'])\n",
    "plt.hist(y_resampled, bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_resampled = pd.DataFrame(data=X_resampled)\n",
    "y_resampled = pd.DataFrame(data=y_resampled)\n",
    "y_resampled.columns=(['target'])\n",
    "train_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "train_resampled = shuffle(train_resampled, random_state=42)\n",
    "train_resampled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_smpl[train_smpl.columns[:2303]], train_smpl['target'], test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(train_smpl[train_smpl.columns[:2303]], train_smpl['target'], test_size=0.792, random_state=42)\n",
    "\n",
    "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(train_resampled[train_resampled.columns[:2303]], train_resampled['target'], test_size=0.33, random_state=42)\n",
    "X_train_res_30, X_test_res_30, y_train_res_30, y_test_res_30 = train_test_split(train_resampled[train_resampled.columns[:2303]], train_resampled['target'], test_size=0.528, random_state=42)\n",
    "X_train_res_70, X_test_res_70, y_train_res_70, y_test_res_70 = train_test_split(train_resampled[train_resampled.columns[:2303]], train_resampled['target'], test_size=0.792, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.concat([X_train, y_train], axis=1, join='inner')\n",
    "test_set = pd.concat([X_test, y_test], axis=1, join='inner')\n",
    "\n",
    "train_set_r70 = pd.concat([X_train_70, y_train_70], axis=1, join='inner')\n",
    "test_set_r70 = pd.concat([X_test_70, y_test_70], axis=1, join='inner')\n",
    "\n",
    "\n",
    "train_set_res = pd.concat([X_train_res, y_train_res], axis=1, join='inner')\n",
    "test_set_res = pd.concat([X_test_res, y_test_res], axis=1, join='inner')\n",
    "\n",
    "train_set_30 = pd.concat([X_train_res_30, y_train_res_30], axis=1, join='inner')\n",
    "test_set_30 = pd.concat([X_test_res_30, y_test_res_30], axis=1, join='inner')\n",
    "\n",
    "train_set_70 = pd.concat([X_train_res_70, y_train_res_70], axis=1, join='inner')\n",
    "test_set_70 = pd.concat([X_test_res_70, y_test_res_70], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_pickle(\"../../data/processed/train_real_set.pkl\")\n",
    "test_set.to_pickle(\"../../data/processed/test_real_set.pkl\")\n",
    "\n",
    "train_set_r70.to_pickle(\"../../data/processed/train_real_set_70.pkl\")\n",
    "test_set_r70.to_pickle(\"../../data/processed/test_real_set_70.pkl\")\n",
    "\n",
    "train_resampled.to_pickle(\"../../data/processed/full_set.pkl\")\n",
    "\n",
    "train_set_res.to_pickle(\"../../data/processed/train_set.pkl\")\n",
    "test_set_res.to_pickle(\"../../data/processed/test_set.pkl\")\n",
    "\n",
    "train_set_30.to_pickle(\"../../data/processed/train_set_30.pkl\")\n",
    "test_set_30.to_pickle(\"../../data/processed/test_set_30.pkl\")\n",
    "\n",
    "train_set_70.to_pickle(\"../../data/processed/train_set_70.pkl\")\n",
    "test_set_70.to_pickle(\"../../data/processed/test_set_70.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "        https://stackoverflow.com/a/50386871\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Original data set\n",
    "plot_confusion_matrix(conf_mat, target_names=y_test.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Resampled data set\n",
    "plot_confusion_matrix(conf_mat_res, target_names=y_test_res.unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
