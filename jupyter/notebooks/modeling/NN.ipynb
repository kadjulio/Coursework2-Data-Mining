{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "        https://stackoverflow.com/a/50386871\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/processed/full_set.pkl', 'rb') as f:\n",
    "    full_set = pickle.load(f)\n",
    "with open('../../data/processed/train_set.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "with open('../../data/processed/test_set.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)\n",
    "with open('../../data/processed/train_set_30.pkl', 'rb') as f:\n",
    "    train_set_30 = pickle.load(f)\n",
    "with open('../../data/processed/test_set_30.pkl', 'rb') as f:\n",
    "    test_set_30 = pickle.load(f)\n",
    "with open('../../data/processed/train_set_70.pkl', 'rb') as f:\n",
    "    train_set_70 = pickle.load(f)\n",
    "with open('../../data/processed/test_set_70.pkl', 'rb') as f:\n",
    "    test_set_70 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_70.head()\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X, y format \n",
    "X_train = train_set.T.iloc[:-1].T\n",
    "y_train = train_set.T.iloc[-1].T\n",
    "\n",
    "X_test = test_set.T.iloc[:-1].T\n",
    "y_test = test_set.T.iloc[-1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm a little suspicious about how complicated the linear kernel is - possibly more than we need.\n",
    "# A multilayer perceptrol with 0 layers is also a linear classifier if we need it.\n",
    "from sklearn.svm import SVC\n",
    "linclf = SVC(kernel=\"linear\")\n",
    "linclf.fit(X_train, y_train) \n",
    "linclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with various Neural Network parameters: add or remove nodes, layers and connections, vary the learning rate, epochs and momentum, and validation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "def get_mlp():\n",
    "    mlp = MLPClassifier(random_state=42\n",
    "                        # more non default parameters? E.g. only stochastic gradient descent has been covered in lectures \n",
    "                        # also doesn't reach convergence before timeout with current settings\n",
    "                       )\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying it using keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import random\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "# https://machinelearningmastery.com/build-multi-layer-perceptron-neural-network-models-keras/\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_keras_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=2303, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # compile the keras model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=100)\n",
    "\n",
    "# evaluate the keras model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "kcls = KerasClassifier(build_fn=build_keras_model, epochs=10, batch_size=100)\n",
    "\n",
    "#Note, if you try running this example in an IPython or Jupyter notebook you may get an error.\n",
    "#The reason is the output progress bars during training. \n",
    "#You can easily turn these off by setting verbose=0 in fit() and evaluate() calls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=42)\n",
    "# todo run this\n",
    "def cross_validate(classifier, X, y):\n",
    "    '''    \n",
    "    Given a classifier and training data:\n",
    "        * Do 10fold CV\n",
    "        * average the scores\n",
    "    What this means is for the caller to interpret.\n",
    "    Returns average result over CV runs \n",
    "    '''\n",
    "    standardising_classifier = make_pipeline(preprocessing.StandardScaler(), classifier)\n",
    "    cross_val_score(standardising_classifier, X, y, cv=10)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running An Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(classifier, X_train_data, y_train_data, X_test_data, y_test_data):\n",
    "    '''\n",
    "    Given a classifier, training data, and test data:\n",
    "    * Train on the training data\n",
    "    * Test on the test data\n",
    "    * display the confusion matrix and other metrics\n",
    "    '''\n",
    "    classifier_pipe = make_pipeline(preprocessing.StandardScaler(), classifier)\n",
    "\n",
    "    classifier_pipe.fit(X_train_data, y_train_data)\n",
    "    y_pred = classifier_pipe.predict(X_test_data)\n",
    "\n",
    "    conf_mat = confusion_matrix(y_test_data, y_pred)\n",
    "    print(classification_report(y_test_data, y_pred))\n",
    "    plot_confusion_matrix(conf_mat, target_names=y_test_data.unique().sort())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original split:\")\n",
    "print(f\"{train_set['target'].shape[0]} training examples\")\n",
    "mlp_max = get_mlp()\n",
    "run_experiment(mlp_max, train_set.iloc[:,:-1], train_set['target'], test_set.iloc[:,:-1], test_set['target'])\n",
    "print(\"------\\n\")\n",
    "\n",
    "\n",
    "print(\"Reduced training set:\")\n",
    "print(f\"{train_set_30['target'].shape[0]} training examples\")\n",
    "mlp_mid = get_mlp()\n",
    "run_experiment(mlp_mid, train_set_30.iloc[:,:-1], train_set_30['target'], test_set_30.iloc[:,:-1], test_set_30['target'])\n",
    "print(\"------\\n\")\n",
    "\n",
    "\n",
    "print(\"Smallest training set\")\n",
    "print(f\"{train_set_70['target'].shape[0]} training examples\")\n",
    "mlp_small = get_mlp()\n",
    "run_experiment(mlp_small, train_set_70.iloc[:,:-1], train_set_70['target'], test_set_70.iloc[:,:-1], test_set_70['target'])\n",
    "print(\"------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... So the results of the previous cell are a bit too good. Let's keep going with the training set reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# half the remaining training data\n",
    "def half_remaining_training_data(train_X, train_y, test_X, test_y):\n",
    "    X_train_tiny, X_test_tiny_tmp, y_train_tiny, y_test_tiny_tmp = train_test_split(train_X, train_y, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Move the new test split into the existing test data\n",
    "    X_test_tiny = pd.concat([X_test_tiny_tmp, test_X], axis=0)\n",
    "    y_test_tiny = pd.concat([y_test_tiny_tmp, test_y], axis=0)\n",
    "                             \n",
    "    return X_train_tiny, X_test_tiny, y_train_tiny, y_test_tiny\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_90, X_test_90, y_train_90, y_test_90 = half_remaining_training_data(train_set_70.iloc[:,:-1], train_set_70['target'], test_set_70.iloc[:,:-1], test_set_70['target'])\n",
    "X_train_95, X_test_95, y_train_95, y_test_95 = half_remaining_training_data(X_train_90, y_train_90, X_test_90, y_test_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"10% training set\")\n",
    "print(f\"{y_train_90.shape[0]} training examples\")\n",
    "mlp_tiny = get_mlp()\n",
    "run_experiment(mlp_tiny, X_train_90, y_train_90, X_test_90, y_test_90)\n",
    "\n",
    "print(\"5% training set\")\n",
    "print(f\"{y_train_95.shape[0]} training examples\")\n",
    "mlp_tinier = get_mlp()\n",
    "run_experiment(mlp_tinier, X_train_95, y_train_95, X_test_95, y_test_95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras model, original data split:\")\n",
    "print(f\"{train_set['target'].shape[0]} training examples\")\n",
    "\n",
    "run_experiment(kcls, train_set.iloc[:,:-1], train_set['target'], test_set.iloc[:,:-1], test_set['target'])\n",
    "print(\"------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/visualization/\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Use confusion matrices as well as other metrics (TP Rate, FP Rate, Precision, Recall, F Measure, ROC Area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
